{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Symbolic Links and Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def delete_symbolic_links(target_dir):\n",
    "    \"\"\"\n",
    "    Delete all symbolic links in the specified directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        print(f\"Directory {target_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    for filename in os.listdir(target_dir):\n",
    "        file_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        # Check if the file is a symbolic link\n",
    "        if os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "            # print(f\"Deleted symbolic link: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped (not a link): {file_path}\")\n",
    "\n",
    "def split_data_and_create_links(source_dirs, train_dir, val_dir, test_dir, positive, split_ratio=(0.6, 0.2, 0.2)):\n",
    "    # Function to create directories and copy links\n",
    "    # This function seems to be having a problem, the symbolic links are being created but they are somehow broken and don't work\n",
    "    def create_dir_and_symlink_files(file_list, source_dir, target_dir):\n",
    "        source_dir = os.path.abspath(source_dir)\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "\n",
    "        for filename in file_list:\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            target_file = os.path.join(target_dir, filename)\n",
    "\n",
    "            if os.path.isfile(source_file) and not os.path.exists(target_file):\n",
    "                os.symlink(source_file, target_file)\n",
    "\n",
    "    # Process each source directory\n",
    "    for source_dir in source_dirs:\n",
    "        if not os.path.exists(source_dir):\n",
    "            print(f\"Source directory {source_dir} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Get all filenames in the source directory\n",
    "        filenames = os.listdir(source_dir)\n",
    "        random.shuffle(filenames)  # Shuffle to randomize distribution\n",
    "\n",
    "        # Calculate split indices\n",
    "        total_files = len(filenames)\n",
    "        train_end = int(total_files * split_ratio[0])\n",
    "        val_end = train_end + int(total_files * split_ratio[1])\n",
    "\n",
    "        # Split filenames into training, validation, and test sets\n",
    "        train_filenames = filenames[:train_end]\n",
    "        val_filenames = filenames[train_end:val_end]\n",
    "        test_filenames = filenames[val_end:]\n",
    "\n",
    "        # Create directories and copy the files\n",
    "        pos_or_neg = 'positive' if positive else 'negative'\n",
    "        create_dir_and_symlink_files(train_filenames, source_dir, os.path.join(train_dir, pos_or_neg))\n",
    "        create_dir_and_symlink_files(val_filenames, source_dir, os.path.join(val_dir, pos_or_neg))\n",
    "        create_dir_and_symlink_files(test_filenames, source_dir, os.path.join(test_dir, pos_or_neg))\n",
    "\n",
    "# Delete old symbolic links:\n",
    "for path in ['../data/train/positive', '../data/train/negative', '../data/val/positive', '../data/val/negative', '../data/test/positive', '../data/test/negative']:\n",
    "    delete_symbolic_links(path)\n",
    "\n",
    "# Source directories\n",
    "pos_image_paths = ['../all_brain_images/manual_label', '../all_brain_images/tumor_dataset']\n",
    "neg_image_paths = ['../all_non_brain/manual_label', '../all_non_brain/ct_scans', '../all_non_brain/rand_geographic']\n",
    "\n",
    "# Split data and create new directories with symbolic links\n",
    "split_data_and_create_links(pos_image_paths, '../data/train', '../data/val', '../data/test', positive=True)\n",
    "split_data_and_create_links(neg_image_paths, '../data/train', '../data/val', '../data/test', positive=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Data augmentation for the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # VGG16 preprocessing\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Only rescaling for the validation and test data\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Paths to train, validation, and test directories\n",
    "train_dir = os.path.normpath('../data/train')\n",
    "val_dir = os.path.normpath('../data/val')\n",
    "test_dir = os.path.normpath('../data/test')\n",
    "\n",
    "\n",
    "# Data generators for train, validation, and test sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Usually, you don't shuffle the test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Load VGG16 model, pre-trained on ImageNet data\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,            # Base model (VGG16)\n",
    "    Flatten(),             # Flatten the output\n",
    "    Dense(256, activation='relu'),  # A dense layer\n",
    "    Dropout(0.5),          # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=num_epochs\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy}, Test loss: {test_loss}\")\n",
    "\n",
    "model.save('../models/brain_img_classifier_1.h5') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
